{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0pP6UN-OJhn",
        "outputId": "7f1f3270-b3b6-4571-affd-2eff1034389f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(Xtrain,ytrain),(Xtest,ytest) = keras.datasets.cifar100.load_data()\n",
        "print(Xtrain.shape,ytrain.shape)\n",
        "print(Xtest.shape,ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the CNN model\n",
        "cnn_model = keras.models.Sequential() # empty framework\n",
        "\n",
        "# Convolutinal layer 1\n",
        "cnn_model.add(keras.layers.Conv2D(60,3,activation='relu',input_shape=(32,32,3)))\n",
        "\n",
        "# maxpooling -1\n",
        "cnn_model.add(keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "# Convolutinal layer 2\n",
        "cnn_model.add(keras.layers.Conv2D(70,3,activation='relu'))\n",
        "\n",
        "# maxpooling -2\n",
        "cnn_model.add(keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "# feed forwards network\n",
        "cnn_model.add(keras.layers.Flatten()) # input layer\n",
        "cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL1\n",
        "cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL2\n",
        "cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL3\n",
        "cnn_model.add(keras.layers.Dense(len(np.unique(ytrain)))) # Output layer\n",
        "\n",
        "# optimizer\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "cnn_model.compile(optimizer='sgd',loss = loss,metrics=['accuracy'])\n",
        "cnn_model.summary()\n",
        "\n",
        "# data scaling\n",
        "Xtrain = Xtrain/Xtrain.max()\n",
        "Xtest = Xtest/Xtest.max()\n",
        "\n",
        "print(len(np.unique(ytrain)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvqlPngxOWaJ",
        "outputId": "40eeba4c-6d11-4e51-9ba1-91c58af5768d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 60)        1680      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 15, 15, 60)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 70)        37870     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 70)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2520)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 200)               504200    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 644250 (2.46 MB)\n",
            "Trainable params: 644250 (2.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the cnn along with the validation data\n",
        "history = cnn_model.fit(Xtrain,ytrain,epochs=120,validation_data=(Xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dGslvvb7PABt",
        "outputId": "63b6917f-8008-4a87-9070-9e880a41e515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "1563/1563 [==============================] - 10s 5ms/step - loss: 4.5885 - accuracy: 0.0167 - val_loss: 4.5267 - val_accuracy: 0.0279\n",
            "Epoch 2/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 4.2598 - accuracy: 0.0520 - val_loss: 4.0683 - val_accuracy: 0.0759\n",
            "Epoch 3/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 3.9837 - accuracy: 0.0894 - val_loss: 3.9404 - val_accuracy: 0.0943\n",
            "Epoch 4/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7830 - accuracy: 0.1218 - val_loss: 3.6921 - val_accuracy: 0.1462\n",
            "Epoch 5/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 3.6173 - accuracy: 0.1527 - val_loss: 3.5963 - val_accuracy: 0.1618\n",
            "Epoch 6/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 3.4661 - accuracy: 0.1791 - val_loss: 3.4378 - val_accuracy: 0.1803\n",
            "Epoch 7/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 3.3286 - accuracy: 0.2036 - val_loss: 3.4298 - val_accuracy: 0.1928\n",
            "Epoch 8/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 3.1980 - accuracy: 0.2256 - val_loss: 3.2682 - val_accuracy: 0.2124\n",
            "Epoch 9/120\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 3.0719 - accuracy: 0.2500 - val_loss: 3.0926 - val_accuracy: 0.2460\n",
            "Epoch 10/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.9533 - accuracy: 0.2715 - val_loss: 3.0640 - val_accuracy: 0.2540\n",
            "Epoch 11/120\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.8464 - accuracy: 0.2913 - val_loss: 3.0867 - val_accuracy: 0.2508\n",
            "Epoch 12/120\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.7463 - accuracy: 0.3100 - val_loss: 2.9683 - val_accuracy: 0.2731\n",
            "Epoch 13/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.6529 - accuracy: 0.3279 - val_loss: 2.8341 - val_accuracy: 0.3020\n",
            "Epoch 14/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5700 - accuracy: 0.3450 - val_loss: 2.8534 - val_accuracy: 0.2988\n",
            "Epoch 15/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4889 - accuracy: 0.3634 - val_loss: 2.8459 - val_accuracy: 0.3072\n",
            "Epoch 16/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4132 - accuracy: 0.3801 - val_loss: 2.7300 - val_accuracy: 0.3299\n",
            "Epoch 17/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3355 - accuracy: 0.3972 - val_loss: 2.7441 - val_accuracy: 0.3250\n",
            "Epoch 18/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2617 - accuracy: 0.4125 - val_loss: 2.6460 - val_accuracy: 0.3463\n",
            "Epoch 19/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 2.1880 - accuracy: 0.4288 - val_loss: 2.6463 - val_accuracy: 0.3481\n",
            "Epoch 20/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1183 - accuracy: 0.4414 - val_loss: 2.6138 - val_accuracy: 0.3522\n",
            "Epoch 21/120\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.0449 - accuracy: 0.4590 - val_loss: 2.6549 - val_accuracy: 0.3457\n",
            "Epoch 22/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9743 - accuracy: 0.4752 - val_loss: 2.5826 - val_accuracy: 0.3642\n",
            "Epoch 23/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9049 - accuracy: 0.4882 - val_loss: 2.6656 - val_accuracy: 0.3540\n",
            "Epoch 24/120\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.8353 - accuracy: 0.5055 - val_loss: 2.6661 - val_accuracy: 0.3637\n",
            "Epoch 25/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7639 - accuracy: 0.5208 - val_loss: 2.7341 - val_accuracy: 0.3566\n",
            "Epoch 26/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6966 - accuracy: 0.5329 - val_loss: 2.6458 - val_accuracy: 0.3602\n",
            "Epoch 27/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6241 - accuracy: 0.5525 - val_loss: 2.6860 - val_accuracy: 0.3708\n",
            "Epoch 28/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5517 - accuracy: 0.5695 - val_loss: 2.7516 - val_accuracy: 0.3673\n",
            "Epoch 29/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4794 - accuracy: 0.5895 - val_loss: 2.7670 - val_accuracy: 0.3711\n",
            "Epoch 30/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4140 - accuracy: 0.6023 - val_loss: 2.8061 - val_accuracy: 0.3667\n",
            "Epoch 31/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3400 - accuracy: 0.6202 - val_loss: 2.8838 - val_accuracy: 0.3636\n",
            "Epoch 32/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2701 - accuracy: 0.6377 - val_loss: 2.9127 - val_accuracy: 0.3722\n",
            "Epoch 33/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1976 - accuracy: 0.6590 - val_loss: 3.0636 - val_accuracy: 0.3513\n",
            "Epoch 34/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1338 - accuracy: 0.6713 - val_loss: 3.0268 - val_accuracy: 0.3688\n",
            "Epoch 35/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.0659 - accuracy: 0.6901 - val_loss: 3.1344 - val_accuracy: 0.3545\n",
            "Epoch 36/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9939 - accuracy: 0.7089 - val_loss: 3.1809 - val_accuracy: 0.3705\n",
            "Epoch 37/120\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9318 - accuracy: 0.7220 - val_loss: 3.4506 - val_accuracy: 0.3422\n",
            "Epoch 38/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8668 - accuracy: 0.7411 - val_loss: 3.5906 - val_accuracy: 0.3537\n",
            "Epoch 39/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8037 - accuracy: 0.7567 - val_loss: 3.6328 - val_accuracy: 0.3459\n",
            "Epoch 40/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7515 - accuracy: 0.7709 - val_loss: 3.6362 - val_accuracy: 0.3641\n",
            "Epoch 41/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6889 - accuracy: 0.7897 - val_loss: 3.8474 - val_accuracy: 0.3513\n",
            "Epoch 42/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6342 - accuracy: 0.8038 - val_loss: 4.0425 - val_accuracy: 0.3503\n",
            "Epoch 43/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5864 - accuracy: 0.8172 - val_loss: 4.4336 - val_accuracy: 0.3397\n",
            "Epoch 44/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5412 - accuracy: 0.8306 - val_loss: 4.3961 - val_accuracy: 0.3263\n",
            "Epoch 45/120\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5054 - accuracy: 0.8402 - val_loss: 4.4561 - val_accuracy: 0.3450\n",
            "Epoch 46/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4566 - accuracy: 0.8538 - val_loss: 4.4831 - val_accuracy: 0.3525\n",
            "Epoch 47/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4238 - accuracy: 0.8649 - val_loss: 4.8039 - val_accuracy: 0.3468\n",
            "Epoch 48/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3980 - accuracy: 0.8723 - val_loss: 5.0249 - val_accuracy: 0.3435\n",
            "Epoch 49/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3664 - accuracy: 0.8821 - val_loss: 5.1551 - val_accuracy: 0.3434\n",
            "Epoch 50/120\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3225 - accuracy: 0.8967 - val_loss: 5.4625 - val_accuracy: 0.3459\n",
            "Epoch 51/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3077 - accuracy: 0.9011 - val_loss: 5.3798 - val_accuracy: 0.3565\n",
            "Epoch 52/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2847 - accuracy: 0.9077 - val_loss: 5.6841 - val_accuracy: 0.3382\n",
            "Epoch 53/120\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.2960 - accuracy: 0.9037 - val_loss: 5.6775 - val_accuracy: 0.3408\n",
            "Epoch 54/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2964 - accuracy: 0.9030 - val_loss: 5.8285 - val_accuracy: 0.3414\n",
            "Epoch 55/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2338 - accuracy: 0.9233 - val_loss: 5.9642 - val_accuracy: 0.3526\n",
            "Epoch 56/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1992 - accuracy: 0.9351 - val_loss: 6.4699 - val_accuracy: 0.3389\n",
            "Epoch 57/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1916 - accuracy: 0.9387 - val_loss: 6.4872 - val_accuracy: 0.3420\n",
            "Epoch 58/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1743 - accuracy: 0.9455 - val_loss: 6.6020 - val_accuracy: 0.3381\n",
            "Epoch 59/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2271 - accuracy: 0.9248 - val_loss: 6.7259 - val_accuracy: 0.3483\n",
            "Epoch 60/120\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2293 - accuracy: 0.9247 - val_loss: 6.7166 - val_accuracy: 0.3466\n",
            "Epoch 61/120\n",
            " 778/1563 [=============>................] - ETA: 3s - loss: 0.1554 - accuracy: 0.9511"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-49ee62693b50>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the cnn along with the validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "otLd66DUPEJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}